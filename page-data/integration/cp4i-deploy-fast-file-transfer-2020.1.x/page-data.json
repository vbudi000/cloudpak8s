{"componentChunkName":"component---src-pages-integration-cp-4-i-deploy-fast-file-transfer-2020-1-x-index-mdx","path":"/integration/cp4i-deploy-fast-file-transfer-2020.1.x/","result":{"pageContext":{"frontmatter":{"title":"Aspera","description":"Basic guide for deploying the Fast File Transfer","keywords":"ibm, install, integration, Aspera, High Speed File Transfer"},"relativePagePath":"/integration/cp4i-deploy-fast-file-transfer-2020.1.x/index.mdx","titleType":"page","MdxNode":{"id":"b620154b-7e44-50b0-ae7d-2abbdd190dce","children":[],"parent":"0e4d2bfc-1af0-564a-8498-141bf9f17980","internal":{"content":"---\ntitle: Aspera\ndescription: Basic guide for deploying the Fast File Transfer\nkeywords: 'ibm, install, integration, Aspera, High Speed File Transfer'\n---\n\n<InlineNotification>\n\nVersion 2020.2 is out for Cloud Pak for Ingegration.  This version is the first to feature Operators and has significant changes to the deployment and operations.  Please refer to the [Knowledge Center](https://www.ibm.com/support/knowledgecenter/en/SSGT7J_20.2/overview.html) while we update this playbook.  Thanks!\n\n</InlineNotification>\n\n<AnchorLinks>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Prepare Installation</AnchorLink>\n  <AnchorLink>Begin Installation</AnchorLink>\n  <AnchorLink>Validate installation</AnchorLink>\n</AnchorLinks>\n\n### **Introduction**\nThis page contains guidance on how to configure the Aspera release for\nboth on-prem and IBM Cloud.\n\n### **Prepare Installation**\n\n1. **Change project to aspera**\n   ```\n   oc project aspera\n   ```\n2. **Use Node Labels:**\n\n    In order to ensure high availability, the Aspera Swarm services will\n    attempt to create a configurable number of pods on each node in the\n    Kubernetes cluster. The nodes on which the receiver pods are running\n    can be restricted via the nodeLabels values.\n\n    For example, the following would restrict pods to nodes with\n    the `node-role.kubernetes.io/ascp=true` label or\n    `node-role.kubernetes.io/noded=true` label.\n\n    ```\n    ascpSwarm:\n    config:\n        nodeLabels:\n        node-role.kubernetes.io/ascp: \"true\"\n\n    nodedSwarm:\n    config:\n        nodeLabels:\n        node-role.kubernetes.io/noded: \"true\"\n    ```\n\n    Label Nodes using the command\n\n    ```\n    oc label node &lt;node-name&gt; node-role.kubernetes.io/&lt;role&gt;=true\n    ```\n\n3. **Additional RBAC Requirements:**\n\n    The following RBAC resources are also required before you deploy the\n    chart. Use the command `oc create -f &lt;filename.yaml&gt;`\n\n    - **Cluster Admin**\n      - [ClusterRole](/assets/img/integration/aspera/files/cluster-admin-clusterrole.yaml)\n    - **Namespace User**\n      Substitute {{ NAMESPACE }} with the namespace the chart will be deployed in.\n      - [ClusterRoleBinding](/assets/img/integration/aspera/files/namespace-user-clusterrole.yaml)\n      - [Role](/assets/img/integration/aspera/files/namespace-user-role.yaml)\n      - [RoleBinding](/assets/img/integration/aspera/files/namespace-user-rolebinding.yaml)\n      - [RoleBinding](/assets/img/integration/aspera/files/hsts-prod-rolebinding.yaml)\n      - [ServiceAccount](/assets/img/integration/aspera/files/apsera-sa-role.yaml) - Set to `ibm-entitlement-key` if using entitled registry or if offline use the `deployer-dockercfg-XX` secret in your namespace.  Use `oc get secrets` to get the value.\n      - [Secret Generation Role](/assets/img/integration/aspera/files/secret-gen-role.yaml)\n      - [Secret Generation RoleBinding](/assets/img/integration/aspera/files/secret-gen-rolebinding.yaml)\n      - [Secret Generation ServiceAccount](/assets/img/integration/aspera/files/secret-gen-sa.yaml)\n\n4. **Create the secrets**\n\n   Make sure you have copied your aspera license key to the location\n   where you will be creating the secrets.  The following command assumes\n   it is named `aspera-license`.\n\n   ```\n   oc create secret generic aspera-server --from -file=ASPERA_LICENSE=\"./aspera-license\" --from-literal=TOKEN_ENCRYPTION_KEY=\"my_encryption_key\"\n\n   kubectl create secret generic asperanode-nodeadmin --from-literal=NODE_USER=\"myuser\" --from-literal=NODE_PASS=\"mypassword\"\n\n   kubectl create secret generic asperanode-accesskey --from-literal=ACCESS_KEY_ID=\"my_access_key\" --from-literal=ACCESS_KEY_SECRET=\"my_access_key_secret\"\n   ```\n\n### **Begin Installation**\n1. Go to CP4I Platform Home. Click **Create instance** inside\nthe **Aspera** tile.\n1. A window will pop up with a description of the requirements for\ninstalling. Click **Continue** to the helm chart deployment configuration.\n2. Click **Overview** to view the chart information and pre-reqs that\nwere covered in [Prepare Installation](#prepare-installation).\n3. Click **Configure**\n4. Enter the Helm release name. In our example, **Aspera-1**\n5. Enter Target Namespace - **Aspera**\n6. Select a Cluster - **local-cluster**.\n7. Tick the license agreement checkbox.\n8. Under Parameters -> Quick start\n   1. Ingress - icp-proxy address defined during icp / common-services installation - icp-proxy.\\&lt;openshift-router-domain&gt;\n   2. Aspera Node - Server Secret - the secret created using the license - `aspera-server`\n   3. Aspera Event Journal - Kafka Host - use hostname of bootstrap server of existing eventstreams installation. Get this value from the Eventstreams web ui.\n   4. Aspera Rproxy - address of cluster proxy.  This can be configured later if need be.\n9.  Click All Parameters\n10. Uncheck production usage\n11. Image Pull Secret - the secret used to pull images for install from\nthe docker registry. Set to `ibm-entitlement-key` if using entitled\nregistry or if offline use the `deployer-dockercfg-XX` secret in your\nnamespace.\n12. Scroll down to the Redis section.\n13. Check Persistence Enabled.\n14. Check Use dynamic provisioning.\n15. Storage Class Name - enter storage class for file storage\n16. Image Pull Secret - same as step 11.\n17. Scroll down to Persistence\n18. Enter the same Storage Class Name as step 15\n19. Proceed to the section Aspera Node\n20. Node Admin Secret - enter the nodeadmin secret created in the preious\nsection - `asperanode-nodeadmin`\n21. Access Key Secret - enter the access key secret created in the previous\nsection - `asperanode-accesskey`\n22. Proceed to the section - Aspera Event Journal\n23. Kafka Port - change to Kafka port found in Eventstreams bootstrapi\nserver.\n24. Proceed to section Ascp Swarm\n25. Node Labels - enter the node labels created in the previous section\nfor identifying ascp swarm nodes -\n   ```\n   {-node-role.kubernetes.io/ascp: true}\n   ```\n26. Proceed to section - Noded Swarm\n27. Node Labels - set to the node label created for noded from the previous section\n   ```\n   {-node-role.kubernetes.io/noded: \"true\"}\n   ```\n28. Scroll to section - Sch\n29. Image Pull Secret - the secret used to pull images for install from\nthe docker registry. Set to `ibm-entitlement-key` if using entitled\nregistry or if offline use the `deployer-dockercfg-XX` secret in your\nnamespace.\n\n### **Validate installation**\n\n1. View all pods running\n    ```\n    NAME                                                       READY     STATUS      RESTARTS   AGE\n    aspera-1-aspera-hsts-aej-d8c5b5569-24vh8                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-aej-d8c5b5569-68nvj                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-aej-d8c5b5569-v5xgb                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-ascp-loadbalancer-75849464b-lq8lz     1/1       Running     0          3m\n    aspera-1-aspera-hsts-ascp-swarm-54c98cb6bb-hznw5           2/2       Running     0          3m\n    aspera-1-aspera-hsts-create-access-key-v1-24hdg            0/1       Completed   0          3m\n    aspera-1-aspera-hsts-http-proxy-8b86df4f-8hd6d             1/1       Running     0          3m\n    aspera-1-aspera-hsts-node-api-796f5c8ccc-r9xs2             2/2       Running     0          3m\n    aspera-1-aspera-hsts-node-master-788774bbc7-8sl2s          2/2       Running     0          3m\n    aspera-1-aspera-hsts-noded-loadbalancer-844977799b-f4gd6   1/1       Running     0          3m\n    aspera-1-aspera-hsts-noded-swarm-6b8498fd-slj8g            2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-4fv4t   2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-d426s   2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-t7f8l   2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-c2gbr                2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-lcbxr                2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-qpj5l                2/2       Running     0          3m\n    aspera-1-aspera-hsts-tcp-proxy-748b6bb64-j478m             1/1       Running     0          3m\n    aspera-1-redis-ha-sentinel-0                               1/1       Running     0          3m\n    aspera-1-redis-ha-sentinel-1                               1/1       Running     0          2m\n    aspera-1-redis-ha-sentinel-2                               1/1       Running     0          1m\n    aspera-1-redis-ha-server-0                                 1/1       Running     0          3m\n    aspera-1-redis-ha-server-1                                 1/1       Running     0          2m\n    aspera-1-redis-ha-server-2                                 1/1       Running     0          2m\n    ```\n","type":"Mdx","contentDigest":"dae6520d37904a89a304d5979c6bed7e","counter":524,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Aspera","description":"Basic guide for deploying the Fast File Transfer","keywords":"ibm, install, integration, Aspera, High Speed File Transfer"},"exports":{},"rawBody":"---\ntitle: Aspera\ndescription: Basic guide for deploying the Fast File Transfer\nkeywords: 'ibm, install, integration, Aspera, High Speed File Transfer'\n---\n\n<InlineNotification>\n\nVersion 2020.2 is out for Cloud Pak for Ingegration.  This version is the first to feature Operators and has significant changes to the deployment and operations.  Please refer to the [Knowledge Center](https://www.ibm.com/support/knowledgecenter/en/SSGT7J_20.2/overview.html) while we update this playbook.  Thanks!\n\n</InlineNotification>\n\n<AnchorLinks>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Prepare Installation</AnchorLink>\n  <AnchorLink>Begin Installation</AnchorLink>\n  <AnchorLink>Validate installation</AnchorLink>\n</AnchorLinks>\n\n### **Introduction**\nThis page contains guidance on how to configure the Aspera release for\nboth on-prem and IBM Cloud.\n\n### **Prepare Installation**\n\n1. **Change project to aspera**\n   ```\n   oc project aspera\n   ```\n2. **Use Node Labels:**\n\n    In order to ensure high availability, the Aspera Swarm services will\n    attempt to create a configurable number of pods on each node in the\n    Kubernetes cluster. The nodes on which the receiver pods are running\n    can be restricted via the nodeLabels values.\n\n    For example, the following would restrict pods to nodes with\n    the `node-role.kubernetes.io/ascp=true` label or\n    `node-role.kubernetes.io/noded=true` label.\n\n    ```\n    ascpSwarm:\n    config:\n        nodeLabels:\n        node-role.kubernetes.io/ascp: \"true\"\n\n    nodedSwarm:\n    config:\n        nodeLabels:\n        node-role.kubernetes.io/noded: \"true\"\n    ```\n\n    Label Nodes using the command\n\n    ```\n    oc label node &lt;node-name&gt; node-role.kubernetes.io/&lt;role&gt;=true\n    ```\n\n3. **Additional RBAC Requirements:**\n\n    The following RBAC resources are also required before you deploy the\n    chart. Use the command `oc create -f &lt;filename.yaml&gt;`\n\n    - **Cluster Admin**\n      - [ClusterRole](/assets/img/integration/aspera/files/cluster-admin-clusterrole.yaml)\n    - **Namespace User**\n      Substitute {{ NAMESPACE }} with the namespace the chart will be deployed in.\n      - [ClusterRoleBinding](/assets/img/integration/aspera/files/namespace-user-clusterrole.yaml)\n      - [Role](/assets/img/integration/aspera/files/namespace-user-role.yaml)\n      - [RoleBinding](/assets/img/integration/aspera/files/namespace-user-rolebinding.yaml)\n      - [RoleBinding](/assets/img/integration/aspera/files/hsts-prod-rolebinding.yaml)\n      - [ServiceAccount](/assets/img/integration/aspera/files/apsera-sa-role.yaml) - Set to `ibm-entitlement-key` if using entitled registry or if offline use the `deployer-dockercfg-XX` secret in your namespace.  Use `oc get secrets` to get the value.\n      - [Secret Generation Role](/assets/img/integration/aspera/files/secret-gen-role.yaml)\n      - [Secret Generation RoleBinding](/assets/img/integration/aspera/files/secret-gen-rolebinding.yaml)\n      - [Secret Generation ServiceAccount](/assets/img/integration/aspera/files/secret-gen-sa.yaml)\n\n4. **Create the secrets**\n\n   Make sure you have copied your aspera license key to the location\n   where you will be creating the secrets.  The following command assumes\n   it is named `aspera-license`.\n\n   ```\n   oc create secret generic aspera-server --from -file=ASPERA_LICENSE=\"./aspera-license\" --from-literal=TOKEN_ENCRYPTION_KEY=\"my_encryption_key\"\n\n   kubectl create secret generic asperanode-nodeadmin --from-literal=NODE_USER=\"myuser\" --from-literal=NODE_PASS=\"mypassword\"\n\n   kubectl create secret generic asperanode-accesskey --from-literal=ACCESS_KEY_ID=\"my_access_key\" --from-literal=ACCESS_KEY_SECRET=\"my_access_key_secret\"\n   ```\n\n### **Begin Installation**\n1. Go to CP4I Platform Home. Click **Create instance** inside\nthe **Aspera** tile.\n1. A window will pop up with a description of the requirements for\ninstalling. Click **Continue** to the helm chart deployment configuration.\n2. Click **Overview** to view the chart information and pre-reqs that\nwere covered in [Prepare Installation](#prepare-installation).\n3. Click **Configure**\n4. Enter the Helm release name. In our example, **Aspera-1**\n5. Enter Target Namespace - **Aspera**\n6. Select a Cluster - **local-cluster**.\n7. Tick the license agreement checkbox.\n8. Under Parameters -> Quick start\n   1. Ingress - icp-proxy address defined during icp / common-services installation - icp-proxy.\\&lt;openshift-router-domain&gt;\n   2. Aspera Node - Server Secret - the secret created using the license - `aspera-server`\n   3. Aspera Event Journal - Kafka Host - use hostname of bootstrap server of existing eventstreams installation. Get this value from the Eventstreams web ui.\n   4. Aspera Rproxy - address of cluster proxy.  This can be configured later if need be.\n9.  Click All Parameters\n10. Uncheck production usage\n11. Image Pull Secret - the secret used to pull images for install from\nthe docker registry. Set to `ibm-entitlement-key` if using entitled\nregistry or if offline use the `deployer-dockercfg-XX` secret in your\nnamespace.\n12. Scroll down to the Redis section.\n13. Check Persistence Enabled.\n14. Check Use dynamic provisioning.\n15. Storage Class Name - enter storage class for file storage\n16. Image Pull Secret - same as step 11.\n17. Scroll down to Persistence\n18. Enter the same Storage Class Name as step 15\n19. Proceed to the section Aspera Node\n20. Node Admin Secret - enter the nodeadmin secret created in the preious\nsection - `asperanode-nodeadmin`\n21. Access Key Secret - enter the access key secret created in the previous\nsection - `asperanode-accesskey`\n22. Proceed to the section - Aspera Event Journal\n23. Kafka Port - change to Kafka port found in Eventstreams bootstrapi\nserver.\n24. Proceed to section Ascp Swarm\n25. Node Labels - enter the node labels created in the previous section\nfor identifying ascp swarm nodes -\n   ```\n   {-node-role.kubernetes.io/ascp: true}\n   ```\n26. Proceed to section - Noded Swarm\n27. Node Labels - set to the node label created for noded from the previous section\n   ```\n   {-node-role.kubernetes.io/noded: \"true\"}\n   ```\n28. Scroll to section - Sch\n29. Image Pull Secret - the secret used to pull images for install from\nthe docker registry. Set to `ibm-entitlement-key` if using entitled\nregistry or if offline use the `deployer-dockercfg-XX` secret in your\nnamespace.\n\n### **Validate installation**\n\n1. View all pods running\n    ```\n    NAME                                                       READY     STATUS      RESTARTS   AGE\n    aspera-1-aspera-hsts-aej-d8c5b5569-24vh8                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-aej-d8c5b5569-68nvj                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-aej-d8c5b5569-v5xgb                   1/1       Running     0          3m\n    aspera-1-aspera-hsts-ascp-loadbalancer-75849464b-lq8lz     1/1       Running     0          3m\n    aspera-1-aspera-hsts-ascp-swarm-54c98cb6bb-hznw5           2/2       Running     0          3m\n    aspera-1-aspera-hsts-create-access-key-v1-24hdg            0/1       Completed   0          3m\n    aspera-1-aspera-hsts-http-proxy-8b86df4f-8hd6d             1/1       Running     0          3m\n    aspera-1-aspera-hsts-node-api-796f5c8ccc-r9xs2             2/2       Running     0          3m\n    aspera-1-aspera-hsts-node-master-788774bbc7-8sl2s          2/2       Running     0          3m\n    aspera-1-aspera-hsts-noded-loadbalancer-844977799b-f4gd6   1/1       Running     0          3m\n    aspera-1-aspera-hsts-noded-swarm-6b8498fd-slj8g            2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-4fv4t   2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-d426s   2/2       Running     0          3m\n    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-t7f8l   2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-c2gbr                2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-lcbxr                2/2       Running     0          3m\n    aspera-1-aspera-hsts-stats-5c5c8cc8fc-qpj5l                2/2       Running     0          3m\n    aspera-1-aspera-hsts-tcp-proxy-748b6bb64-j478m             1/1       Running     0          3m\n    aspera-1-redis-ha-sentinel-0                               1/1       Running     0          3m\n    aspera-1-redis-ha-sentinel-1                               1/1       Running     0          2m\n    aspera-1-redis-ha-sentinel-2                               1/1       Running     0          1m\n    aspera-1-redis-ha-server-0                                 1/1       Running     0          3m\n    aspera-1-redis-ha-server-1                                 1/1       Running     0          2m\n    aspera-1-redis-ha-server-2                                 1/1       Running     0          2m\n    ```\n","fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/cloudpak8s/src/pages/integration/cp4i-deploy-fast-file-transfer-2020.1.x/index.mdx"}}}}