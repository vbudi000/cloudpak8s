{"componentChunkName":"component---src-pages-day-2-storage-index-mdx","path":"/day2/Storage/","result":{"pageContext":{"frontmatter":{"title":"OpenShift Platform Day2 - Storage","description":"OpenShift Day2 Storage","keywords":"OpenShift, day2, storage"},"relativePagePath":"/day2/Storage/index.mdx","titleType":"page","MdxNode":{"id":"8098e442-9c9e-54aa-b93b-1dc8728a0c6e","children":[],"parent":"fb2b02a0-a6aa-59e1-a9c4-5b2ed66aa0a2","internal":{"content":"---\ntitle: OpenShift Platform Day2 - Storage\ndescription: OpenShift Day2 Storage\nkeywords: 'OpenShift, day2, storage'\n---\n\n## Storage Overview\n\nOpenShift Container Platform uses the kubernetes Persistent Volume (PV) framework that abstracts details of how storage is provided from how it is consumed. This is mainly done by two kubernetes API resources: PersistentVolumes and PersistentVolume Claims. \n\nPersistent Volumes (PV) are storage units that have been provisioned by an administrator or dynamically provisioned using Storage Classes. They are independent of any single pod, breaking them free from the ephemeral life cycle of pods. At its core, a volume is just a directory, possibly with some data in it, which is accessible to the containers in a pod. How that directory comes to be, the medium that backs it, and the contents of it are determined by the particular volume type used.\n\nPersistent Volume Claims (PVC), on the other hand, are requests for the storage, i.e. PVs. Developers can use Persistent Volume Claims (PVCs) to request PV resources without having specific knowledge of the underlying storage infrastructure.\n\nThere are two ways of dealing with kubernetes storage: static or dynamic which is more commonly used.\n\nWith static provisioning, administrators provision PVs that they think pods might require before the actual requests are made, and these PVs are manually bound to specific pods with explicit PVCs.\n\nDynamic provisioning is done with Storage Classes. Cluster administrators do not need to manually create the PVs beforehand. They instead create multiple profiles of storage, just like templates. When a developer makes a PVC, depending on the requirements of the request, one of these storage classes is used at the time of the request in order to dynamically provision the PV.\n\nThe interaction between PVs and PVCs have the following lifecycle:\n\n- [Provision storage](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#provisioning_understanding-persistent-storage)\n- [Bind claims](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#binding_understanding-persistent-storage)\n- [Use Pods and claimed PVs](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#using-pods_understanding-persistent-storage)\n- [Storage Object in Use Protection](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#pvcprotection_understanding-persistent-storage)\n- [Release volumes](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#releasing_understanding-persistent-storage)\n- [Reclaim volumes](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#reclaiming_understanding-persistent-storage)\n\nOpenShift Container Platform 4.3 supports the following PersistentVolume plug-ins:\n- AWS Elastic Block Store (EBS)\n- Azure Disk\n- Azure File\n- Cinder\n- Fibre Channel\n- GCE Persistent Disk\n- HostPath\n- iSCSI\n- Local volume\n- NFS\n- Red Hat OpenShift Container Storage\n- VMware vSphere \n\n\n## Day 1 Platform\n\nThe Storage type used within OpenShift cluster is determined by the place where you decided to deploy your cluster (on-prem or cloud provider like IBM Cloud, AWS, Google Cloud, Azure) and by specific requirements of the workloads running on the cluster(s) like speed/iops or type like block, file or object storage. RedHat OpenShift 4.3 supports several [types](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#types-of-persistent-volumes_understanding-persistent-storage) of storage and some of them are backed up by networked storage system such as EBS, NFS or Ceph and other are locally attached storage like Local Volume or HostPath.\nThe storage type used by the cluster and initial definition of storage classes should be part of the design and implementation phases (Day 0 and Day 1).\n\n**Day 1 Platform tasks for Storage:**\n- Determine the initial storage requirements\n- Define the initial set of StorageClass resources  \n\n\n## Day 2 Platform\n\nThe following Day 2 Operations tasks for OpenShift platform are related to storage:\n\n- [Adding a new StorageClass](#Adding-a-new-StorageClass)\n- [Changing a default StorageClass](#Changing-a-default-StorageClass)\n- [Provisioning Persistent Volumes](#Provisioning-Persistent-Volumes)\n  - [Static Provisioning](#Static-Provisioning)\n  - [Dynamic Provisioning](#Dynamic-Provisioning)\n- [Storage Monitoring](#Storage-Monitoring)\n- [Expanding persistent volumes](https://docs.openshift.com/container-platform/4.3/storage/expanding-persistent-volumes.html)\n- [Persistent Volume backup](#Persistent-Volume-backup)\n\n\n## Day 1 Application\n\nWithout storing data in a persistent volume, the file system of a container is ephemeral. When a container restarts, the file system is reset to whatever the file system state is in the container’s image and files not stored in a persistent volume don’t survive the restart.\n\nEnterprise application workloads frequently need a sustainable and supportable way to store data and objects in flight or as output from your applications, while taking advantage of the portability, scalability, and recoverability of containers. Instead of fighting the natural tendency of containers to be stateless and lightweight, the pattern looks to augment Kubernetes to facilitate the behaviors we want.\n\nThere are many types of storage depending on application requirements: \n- Block storage: (ex. Elastic Block Store (EBS))\n- File storage: (ex. Elastic File System (EFS))\n- Object storage:  (ex. Simple Storage Service (S3))\n\nEach of these offerings has individual performance characteristics, pros, and cons. You must align your application and workload with the proper type of storage for its needs. As part of the Day 0 and Day 1 you should also estimate the initial storage space needed for application workload.\n\n**Day 1 Application tasks for Storage:**\n- Estimate the initial storage space needed for application workload\n- Determine the storage type requirements for applications  \n\n\n## Day 2 Application\n\nThe following Day 2 Operations tasks for OpenShift applications are related to storage:\n\n- [Setting storage quota per project](#Setting-storage-quota-per-project--SRE-DevOps)\n- [Expanding Persistent Volumes](https://docs.openshift.com/container-platform/4.3/storage/expanding-persistent-volumes.html)\n- [Application Storage Monitoring](#Application-storage-monitoring--SRE-DevOps)\n\n## Mapping to Personas\n\nPersona | task\n--- | ---\nSRE, Storage Administrator | Adding a new StorageClass\nSRE, Storage Administrator | Changing a default StorageClass\nSRE, Storage Administrator | Static Provisioning\nSRE, Storage Administrator | Backing up Persistent Volumes\nSRE, Storage Administrator | Expanding Persistent Volumes\nSRE, Storage Administrator | Setting storage quota per project\nSRE, Storage Administrator | Storage Monitoring\nSRE, DevOps Engineer | Application Storage Monitoring\nDevOps Engineer | Dynamic Provisioning   \n\n\n\n## Day 2 Operations Tasks for Storage\n\n<a name=\"Adding-a-new-StorageClass\"></a>\n\n## Adding a new StorageClass: [ SRE ]\n\nThe `StorageClass` resource object describes and classifies storage that can be requested, as well as provides a means for passing parameters for dynamically provisioned storage on demand.  StorageClass objects can also serve as a management mechanism for controlling different levels of storage and access to the storage. SREs or Storage Administrators (storage-admin) define and create the StorageClass objects that users can request without needing any intimate knowledge about the underlying storage volume sources.\nStorageClass objects are a globally scoped object and must be created by `cluster-admin` or `storage-admin` users.\n[OpenShift 4.3 documentation specifies how to define StorageClass objects for various types of supported storage](https://docs.openshift.com/container-platform/4.3/storage/dynamic-provisioning.html#defining-storage-classes_dynamic-provisioning).  \n\n\n\n<a name=\"Changing-a-default-StorageClass\"></a>\n\n## Changing a default StorageClass: [ SRE ]\nThe default StorageClass is used to dynamically provision storage for PersistentVolumeClaims that do not require any specific storage class. A new StorageClass can be marked as a new default by adding the following annotation:\n```\noc patch storageclass <your-class-name> -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n```\n\n## Provisioning Persistent Volumes\nThere are two ways PVs may be provisioned: statically or dynamically.\n\n<a name=\"Static-Provisioning\"></a>\n\n### Static Provisioning: [ SRE ]\nA cluster administrator creates a number of PVs. They carry the details of the real storage, which is available for use by cluster users. They exist in the Kubernetes API and are available for consumption.\nStatic provisioning is a feature that is native to Kubernetes and that allows cluster administrators to make existing storage devices available to a cluster. As a cluster administrator, you must know the details of the storage device, its supported configurations, and mount options.\n\nTo make existing storage available to a cluster user, you must manually create the storage device, a PV, and a PVC.\n\nThe following image shows how to statically provision file storage in a cluster. This sample flow works similar with other storage types, such as block storage.\n\n![](./images/2020-02-26-11-16-12.png)\n\n1. The cluster admin gathers all the details about the existing storage device and creates a persistent volume (PV) in the cluster.\n2. Based on the storage details in the PV, the storage plug-in connects the PV with the storage device.\n3. The cluster admin or a developer creates a PVC. Because the PV and the storage device already exist, no storage class is specified in the PVC.\n4. After the PVC is created, the storage plug-in tries to match the PVC to an existing PV. When PVC and PV match, the status of the PVC and the PV changes to `Bound`. You can now use the PVC to mount persistent storage to your app. When you delete the PVC, the PV and the physical storage instance are not removed. You must remove the PVC, PV, and the physical storage instance separately.\n\nThe process described above can be automated and partially managed by the OpenShift Operators. For example provisioning of `Local Volume` storage is managed by the `Local Storage Operator`. The Local Storage Operator automatically creates Persistent Volumes on local disk devices attached to Nodes and StorageClass that can be used during definition of Persistent Volume Claims. When PVs are ready, the SRE or DevOps Engineer can statically create a PVC using StorageClass for Local Volume Storage. [More details about Local Volume storage with practical examples](./Local/).  \n\n\n<a name=\"Dynamic-Provisioning\"></a>\n\n### Dynamic Provisioning: [ DevOps Engineer ]\nDynamic volume provisioning allows storage volumes to be created on-demand. The dynamic provisioning feature eliminates the need for cluster administrators to pre-provision storage. Instead, it automatically provisions storage when it is requested by OpenShift cluster users like developers. The implementation of dynamic volume provisioning is based on the API object `StorageClass`. [To enable dynamic provisioning, a cluster administrator needs to pre-create one or more StorageClass objects for users](#Adding-a-new-StorageClass). \nCluster Admins, SREs or users request dynamically provisioned storage by including a storage class in their `PersistentVolumeClaim`. Dynamic provisioning can be enabled on a cluster such that all claims are dynamically provisioned if no storage class is specified. A cluster administrator can enable this behavior by [marking one StorageClass object as default](#Changing-a-default-StorageClass).  \n\n\n<a name=\"Storage-Monitoring\"></a>\n\n## Storage Monitoring: [ SRE ]\n \nInformation about current PVC utilization is provided by both `kubelet` and `kube_state_metrics` in the form of Prometheus metrics. \nSREs should monitor the following metrics related to PVC utilization and PV status.\n\nResource | Metrics\n--- | ---\nPVC | kubelet_volume_stats_available_bytes\nPVC | kubelet_volume_stats_capacity_bytes\nPVC | kubelet_volume_stats_used_bytes\nPVC | kubelet_volume_stats_inodes_used\nPVC | kubelet_volume_stats_inodes_free\nPVC | kubelet_volume_stats_inodes\nPV  | kube_persistentvolume_status_phase\n\n\nThe following PromQL query calculates the percentage utilization of PVCs:\n\n```\nkubelet_volume_stats_used_bytes/kubelet_volume_stats_capacity_bytes*100\n```\n\nHere is a sample screen shot of the Prometheus console with results of the query listed above.\n\n![](./images/2020-02-26-19-29-14.png)\n\nAlerts related to storage, predefined in OpenShift:\n\n|Alert | Rule |\n|---|---|\n| KubePersistentVolumeErrors | `kube_persistentvolume_status_phase{job=\"kube-state-metrics\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\",phase=~\"Failed\\|Pending\"} > 0` |\n| KubePersistentVolumeFullInFourDays | `(kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"}) < 0.15 and predict_linear(kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"}[6h], 4 * 24 * 3600) < 0` |\n| KubePersistentVolumeUsageCritical | `kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} < 0.03` |\n\nParticular storage solutions also may provide additional monitoring metrics and dashboards. More information about [Rook Ceph monitoring](https://github.com/rook/rook/blob/master/Documentation/ceph-monitoring.md). Example Rook Ceph Cluster Grafana dashboard is shown below.  \n\n![](./images/2020-02-27-09-23-25.png)    \n\n\n<a name=\"Persistent-Volume-backup\"></a>\n\n## Persistent Volume backup [ SRE ]\n\nOpenShift does not provide a Persistent Volume backup tooling. One of the backup options is to use third party tools [Velero](https://velero.io) or [Stash](https://stash.run/).   \nAnother option may be building a custom solution like in the following example: [How to backup, clone and migrate Persistent Volume Claims on OpenShift](https://blog.openshift.com/how-to-backup-clone-and-migrate-persistent-volume-claims-on-openshift/).\n\n<a name=\"Setting-storage-quota-per-project--SRE-DevOps\"></a>\n\n## Setting storage quota per project [ SRE, DevOps Engineer ]\n\nA resource quota, defined by a ResourceQuota object, provides constraints that limit aggregate resource consumption per project. It can limit the quantity of objects that can be created in a project by type, as well as the total amount of compute resources and storage that may be consumed by resources in that project.\n\nExample storage quota for a given project:\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: storage-consumption\nspec:\n  hard:\n    persistentvolumeclaims: \"10\" \n    requests.storage: \"50Gi\" \n    gold.storageclass.storage.k8s.io/requests.storage: \"10Gi\" \n    silver.storageclass.storage.k8s.io/requests.storage: \"20Gi\" \n    silver.storageclass.storage.k8s.io/persistentvolumeclaims: \"5\" \n```\nAfter a resource quota for a project is first created, the project restricts the ability to create any new resources that may violate a quota constraint until it has calculated updated usage statistics.\n[More information about OpenShift project quotas](https://docs.openshift.com/container-platform/4.3/applications/quotas/quotas-setting-per-project.html).\n\n<a name=\"Application-storage-monitoring--SRE-DevOps\"></a>\n\n## Application storage monitoring [ SRE, DevOps Engineer]\nThe storage space for specific projects and applications is assigned via specific `PersistentVolumeClaims` and can be monitored using OpenShift platform metrics described in [Storage Monitoring](#Storage-Monitoring). Mentioned metrics like `kubelet_volume_stats_used_bytes` can be filtered/aggregated by namespace name or PVC name. For example the following query returns total PVC storage usage in GB for all `humio-data.*` PVCs in the project `humio`:\n```\nsum(kubelet_volume_stats_used_bytes{namespace=\"humio\", persistentvolumeclaim=~\"humio-data.*\"}/1024/1024/1024)\n```\n\n## Storage configuration examples\n\n- [IBM Cloud](ibmcloud)\n- [Local Volumes](./Local/)\n- [Ceph Block Storage via Container Storage Interface](ceph-csi)\n- [VMware vSphere](vmware)\n- [OpenShift Container Storage](openshift-container-storage)\n","type":"Mdx","contentDigest":"509ffff5e8953c7a827030399eb5dd88","counter":548,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"OpenShift Platform Day2 - Storage","description":"OpenShift Day2 Storage","keywords":"OpenShift, day2, storage"},"exports":{},"rawBody":"---\ntitle: OpenShift Platform Day2 - Storage\ndescription: OpenShift Day2 Storage\nkeywords: 'OpenShift, day2, storage'\n---\n\n## Storage Overview\n\nOpenShift Container Platform uses the kubernetes Persistent Volume (PV) framework that abstracts details of how storage is provided from how it is consumed. This is mainly done by two kubernetes API resources: PersistentVolumes and PersistentVolume Claims. \n\nPersistent Volumes (PV) are storage units that have been provisioned by an administrator or dynamically provisioned using Storage Classes. They are independent of any single pod, breaking them free from the ephemeral life cycle of pods. At its core, a volume is just a directory, possibly with some data in it, which is accessible to the containers in a pod. How that directory comes to be, the medium that backs it, and the contents of it are determined by the particular volume type used.\n\nPersistent Volume Claims (PVC), on the other hand, are requests for the storage, i.e. PVs. Developers can use Persistent Volume Claims (PVCs) to request PV resources without having specific knowledge of the underlying storage infrastructure.\n\nThere are two ways of dealing with kubernetes storage: static or dynamic which is more commonly used.\n\nWith static provisioning, administrators provision PVs that they think pods might require before the actual requests are made, and these PVs are manually bound to specific pods with explicit PVCs.\n\nDynamic provisioning is done with Storage Classes. Cluster administrators do not need to manually create the PVs beforehand. They instead create multiple profiles of storage, just like templates. When a developer makes a PVC, depending on the requirements of the request, one of these storage classes is used at the time of the request in order to dynamically provision the PV.\n\nThe interaction between PVs and PVCs have the following lifecycle:\n\n- [Provision storage](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#provisioning_understanding-persistent-storage)\n- [Bind claims](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#binding_understanding-persistent-storage)\n- [Use Pods and claimed PVs](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#using-pods_understanding-persistent-storage)\n- [Storage Object in Use Protection](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#pvcprotection_understanding-persistent-storage)\n- [Release volumes](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#releasing_understanding-persistent-storage)\n- [Reclaim volumes](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#reclaiming_understanding-persistent-storage)\n\nOpenShift Container Platform 4.3 supports the following PersistentVolume plug-ins:\n- AWS Elastic Block Store (EBS)\n- Azure Disk\n- Azure File\n- Cinder\n- Fibre Channel\n- GCE Persistent Disk\n- HostPath\n- iSCSI\n- Local volume\n- NFS\n- Red Hat OpenShift Container Storage\n- VMware vSphere \n\n\n## Day 1 Platform\n\nThe Storage type used within OpenShift cluster is determined by the place where you decided to deploy your cluster (on-prem or cloud provider like IBM Cloud, AWS, Google Cloud, Azure) and by specific requirements of the workloads running on the cluster(s) like speed/iops or type like block, file or object storage. RedHat OpenShift 4.3 supports several [types](https://docs.openshift.com/container-platform/4.3/storage/understanding-persistent-storage.html#types-of-persistent-volumes_understanding-persistent-storage) of storage and some of them are backed up by networked storage system such as EBS, NFS or Ceph and other are locally attached storage like Local Volume or HostPath.\nThe storage type used by the cluster and initial definition of storage classes should be part of the design and implementation phases (Day 0 and Day 1).\n\n**Day 1 Platform tasks for Storage:**\n- Determine the initial storage requirements\n- Define the initial set of StorageClass resources  \n\n\n## Day 2 Platform\n\nThe following Day 2 Operations tasks for OpenShift platform are related to storage:\n\n- [Adding a new StorageClass](#Adding-a-new-StorageClass)\n- [Changing a default StorageClass](#Changing-a-default-StorageClass)\n- [Provisioning Persistent Volumes](#Provisioning-Persistent-Volumes)\n  - [Static Provisioning](#Static-Provisioning)\n  - [Dynamic Provisioning](#Dynamic-Provisioning)\n- [Storage Monitoring](#Storage-Monitoring)\n- [Expanding persistent volumes](https://docs.openshift.com/container-platform/4.3/storage/expanding-persistent-volumes.html)\n- [Persistent Volume backup](#Persistent-Volume-backup)\n\n\n## Day 1 Application\n\nWithout storing data in a persistent volume, the file system of a container is ephemeral. When a container restarts, the file system is reset to whatever the file system state is in the container’s image and files not stored in a persistent volume don’t survive the restart.\n\nEnterprise application workloads frequently need a sustainable and supportable way to store data and objects in flight or as output from your applications, while taking advantage of the portability, scalability, and recoverability of containers. Instead of fighting the natural tendency of containers to be stateless and lightweight, the pattern looks to augment Kubernetes to facilitate the behaviors we want.\n\nThere are many types of storage depending on application requirements: \n- Block storage: (ex. Elastic Block Store (EBS))\n- File storage: (ex. Elastic File System (EFS))\n- Object storage:  (ex. Simple Storage Service (S3))\n\nEach of these offerings has individual performance characteristics, pros, and cons. You must align your application and workload with the proper type of storage for its needs. As part of the Day 0 and Day 1 you should also estimate the initial storage space needed for application workload.\n\n**Day 1 Application tasks for Storage:**\n- Estimate the initial storage space needed for application workload\n- Determine the storage type requirements for applications  \n\n\n## Day 2 Application\n\nThe following Day 2 Operations tasks for OpenShift applications are related to storage:\n\n- [Setting storage quota per project](#Setting-storage-quota-per-project--SRE-DevOps)\n- [Expanding Persistent Volumes](https://docs.openshift.com/container-platform/4.3/storage/expanding-persistent-volumes.html)\n- [Application Storage Monitoring](#Application-storage-monitoring--SRE-DevOps)\n\n## Mapping to Personas\n\nPersona | task\n--- | ---\nSRE, Storage Administrator | Adding a new StorageClass\nSRE, Storage Administrator | Changing a default StorageClass\nSRE, Storage Administrator | Static Provisioning\nSRE, Storage Administrator | Backing up Persistent Volumes\nSRE, Storage Administrator | Expanding Persistent Volumes\nSRE, Storage Administrator | Setting storage quota per project\nSRE, Storage Administrator | Storage Monitoring\nSRE, DevOps Engineer | Application Storage Monitoring\nDevOps Engineer | Dynamic Provisioning   \n\n\n\n## Day 2 Operations Tasks for Storage\n\n<a name=\"Adding-a-new-StorageClass\"></a>\n\n## Adding a new StorageClass: [ SRE ]\n\nThe `StorageClass` resource object describes and classifies storage that can be requested, as well as provides a means for passing parameters for dynamically provisioned storage on demand.  StorageClass objects can also serve as a management mechanism for controlling different levels of storage and access to the storage. SREs or Storage Administrators (storage-admin) define and create the StorageClass objects that users can request without needing any intimate knowledge about the underlying storage volume sources.\nStorageClass objects are a globally scoped object and must be created by `cluster-admin` or `storage-admin` users.\n[OpenShift 4.3 documentation specifies how to define StorageClass objects for various types of supported storage](https://docs.openshift.com/container-platform/4.3/storage/dynamic-provisioning.html#defining-storage-classes_dynamic-provisioning).  \n\n\n\n<a name=\"Changing-a-default-StorageClass\"></a>\n\n## Changing a default StorageClass: [ SRE ]\nThe default StorageClass is used to dynamically provision storage for PersistentVolumeClaims that do not require any specific storage class. A new StorageClass can be marked as a new default by adding the following annotation:\n```\noc patch storageclass <your-class-name> -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n```\n\n## Provisioning Persistent Volumes\nThere are two ways PVs may be provisioned: statically or dynamically.\n\n<a name=\"Static-Provisioning\"></a>\n\n### Static Provisioning: [ SRE ]\nA cluster administrator creates a number of PVs. They carry the details of the real storage, which is available for use by cluster users. They exist in the Kubernetes API and are available for consumption.\nStatic provisioning is a feature that is native to Kubernetes and that allows cluster administrators to make existing storage devices available to a cluster. As a cluster administrator, you must know the details of the storage device, its supported configurations, and mount options.\n\nTo make existing storage available to a cluster user, you must manually create the storage device, a PV, and a PVC.\n\nThe following image shows how to statically provision file storage in a cluster. This sample flow works similar with other storage types, such as block storage.\n\n![](./images/2020-02-26-11-16-12.png)\n\n1. The cluster admin gathers all the details about the existing storage device and creates a persistent volume (PV) in the cluster.\n2. Based on the storage details in the PV, the storage plug-in connects the PV with the storage device.\n3. The cluster admin or a developer creates a PVC. Because the PV and the storage device already exist, no storage class is specified in the PVC.\n4. After the PVC is created, the storage plug-in tries to match the PVC to an existing PV. When PVC and PV match, the status of the PVC and the PV changes to `Bound`. You can now use the PVC to mount persistent storage to your app. When you delete the PVC, the PV and the physical storage instance are not removed. You must remove the PVC, PV, and the physical storage instance separately.\n\nThe process described above can be automated and partially managed by the OpenShift Operators. For example provisioning of `Local Volume` storage is managed by the `Local Storage Operator`. The Local Storage Operator automatically creates Persistent Volumes on local disk devices attached to Nodes and StorageClass that can be used during definition of Persistent Volume Claims. When PVs are ready, the SRE or DevOps Engineer can statically create a PVC using StorageClass for Local Volume Storage. [More details about Local Volume storage with practical examples](./Local/).  \n\n\n<a name=\"Dynamic-Provisioning\"></a>\n\n### Dynamic Provisioning: [ DevOps Engineer ]\nDynamic volume provisioning allows storage volumes to be created on-demand. The dynamic provisioning feature eliminates the need for cluster administrators to pre-provision storage. Instead, it automatically provisions storage when it is requested by OpenShift cluster users like developers. The implementation of dynamic volume provisioning is based on the API object `StorageClass`. [To enable dynamic provisioning, a cluster administrator needs to pre-create one or more StorageClass objects for users](#Adding-a-new-StorageClass). \nCluster Admins, SREs or users request dynamically provisioned storage by including a storage class in their `PersistentVolumeClaim`. Dynamic provisioning can be enabled on a cluster such that all claims are dynamically provisioned if no storage class is specified. A cluster administrator can enable this behavior by [marking one StorageClass object as default](#Changing-a-default-StorageClass).  \n\n\n<a name=\"Storage-Monitoring\"></a>\n\n## Storage Monitoring: [ SRE ]\n \nInformation about current PVC utilization is provided by both `kubelet` and `kube_state_metrics` in the form of Prometheus metrics. \nSREs should monitor the following metrics related to PVC utilization and PV status.\n\nResource | Metrics\n--- | ---\nPVC | kubelet_volume_stats_available_bytes\nPVC | kubelet_volume_stats_capacity_bytes\nPVC | kubelet_volume_stats_used_bytes\nPVC | kubelet_volume_stats_inodes_used\nPVC | kubelet_volume_stats_inodes_free\nPVC | kubelet_volume_stats_inodes\nPV  | kube_persistentvolume_status_phase\n\n\nThe following PromQL query calculates the percentage utilization of PVCs:\n\n```\nkubelet_volume_stats_used_bytes/kubelet_volume_stats_capacity_bytes*100\n```\n\nHere is a sample screen shot of the Prometheus console with results of the query listed above.\n\n![](./images/2020-02-26-19-29-14.png)\n\nAlerts related to storage, predefined in OpenShift:\n\n|Alert | Rule |\n|---|---|\n| KubePersistentVolumeErrors | `kube_persistentvolume_status_phase{job=\"kube-state-metrics\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\",phase=~\"Failed\\|Pending\"} > 0` |\n| KubePersistentVolumeFullInFourDays | `(kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"}) < 0.15 and predict_linear(kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"}[6h], 4 * 24 * 3600) < 0` |\n| KubePersistentVolumeUsageCritical | `kubelet_volume_stats_available_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\",namespace=~\"(openshift-.*\\|kube-.*\\|default\\|logging)\"} < 0.03` |\n\nParticular storage solutions also may provide additional monitoring metrics and dashboards. More information about [Rook Ceph monitoring](https://github.com/rook/rook/blob/master/Documentation/ceph-monitoring.md). Example Rook Ceph Cluster Grafana dashboard is shown below.  \n\n![](./images/2020-02-27-09-23-25.png)    \n\n\n<a name=\"Persistent-Volume-backup\"></a>\n\n## Persistent Volume backup [ SRE ]\n\nOpenShift does not provide a Persistent Volume backup tooling. One of the backup options is to use third party tools [Velero](https://velero.io) or [Stash](https://stash.run/).   \nAnother option may be building a custom solution like in the following example: [How to backup, clone and migrate Persistent Volume Claims on OpenShift](https://blog.openshift.com/how-to-backup-clone-and-migrate-persistent-volume-claims-on-openshift/).\n\n<a name=\"Setting-storage-quota-per-project--SRE-DevOps\"></a>\n\n## Setting storage quota per project [ SRE, DevOps Engineer ]\n\nA resource quota, defined by a ResourceQuota object, provides constraints that limit aggregate resource consumption per project. It can limit the quantity of objects that can be created in a project by type, as well as the total amount of compute resources and storage that may be consumed by resources in that project.\n\nExample storage quota for a given project:\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: storage-consumption\nspec:\n  hard:\n    persistentvolumeclaims: \"10\" \n    requests.storage: \"50Gi\" \n    gold.storageclass.storage.k8s.io/requests.storage: \"10Gi\" \n    silver.storageclass.storage.k8s.io/requests.storage: \"20Gi\" \n    silver.storageclass.storage.k8s.io/persistentvolumeclaims: \"5\" \n```\nAfter a resource quota for a project is first created, the project restricts the ability to create any new resources that may violate a quota constraint until it has calculated updated usage statistics.\n[More information about OpenShift project quotas](https://docs.openshift.com/container-platform/4.3/applications/quotas/quotas-setting-per-project.html).\n\n<a name=\"Application-storage-monitoring--SRE-DevOps\"></a>\n\n## Application storage monitoring [ SRE, DevOps Engineer]\nThe storage space for specific projects and applications is assigned via specific `PersistentVolumeClaims` and can be monitored using OpenShift platform metrics described in [Storage Monitoring](#Storage-Monitoring). Mentioned metrics like `kubelet_volume_stats_used_bytes` can be filtered/aggregated by namespace name or PVC name. For example the following query returns total PVC storage usage in GB for all `humio-data.*` PVCs in the project `humio`:\n```\nsum(kubelet_volume_stats_used_bytes{namespace=\"humio\", persistentvolumeclaim=~\"humio-data.*\"}/1024/1024/1024)\n```\n\n## Storage configuration examples\n\n- [IBM Cloud](ibmcloud)\n- [Local Volumes](./Local/)\n- [Ceph Block Storage via Container Storage Interface](ceph-csi)\n- [VMware vSphere](vmware)\n- [OpenShift Container Storage](openshift-container-storage)\n","fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/cloudpak8s/src/pages/day2/Storage/index.mdx"}}}}