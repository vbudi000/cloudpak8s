{"componentChunkName":"component---src-pages-day-2-metering-index-mdx","path":"/day2/Metering/","result":{"pageContext":{"frontmatter":{"title":"OpenShift Platform Day2 - Metering","description":"OpenShift Day2 Metering","keywords":"OpenShift, day2, metering"},"relativePagePath":"/day2/Metering/index.mdx","titleType":"page","MdxNode":{"id":"5be086b7-0775-5c21-87ad-42ce7df38197","children":[],"parent":"13ef122e-9343-586a-a0c3-3d340da8840f","internal":{"content":"---\ntitle: OpenShift Platform Day2 - Metering\ndescription: OpenShift Day2 Metering\nkeywords: 'OpenShift, day2, metering'\n---\n\n## Metering Overview\nMetering is an essential tool for organizations that use capacity from a Kubernetes cluster to run their services, as well as for IT departments that manage these clusters. In the past, many departments tended to overestimate their resource needs. This could easily result in wasted capacity and wasted capital.\n\nManagement teams want to understand more concretely where budget is spent and by whom, and for which service. Metering provides that information, providing an understanding of how much it costs to run specific services, while also providing usage information that can lead to improved budgeting and capacity planning. With this information, IT Operation can also internally bill departments to reflect the costs directly associated with their actual infrastructure usage, driving accountability for service costs. This helps to eliminate some of the more manual IT “plumbing” work in tallying costs and usage by hand or managing spreadsheets. By using metering, IT teams can free up their time to tackle bigger problems and even drive business-wide innovation.  \n\nHere are some examples of how metering could be applied in the real world:  \n- Cloud budgeting: Teams can gain insight into how cloud resources are being used, especially in autoscaled clusters or hybrid cloud deployments.  \n- Cloud billing: Resource usage can be tracked by billing codes or labels that reflect your internal hierarchy.\n- Telemetry/aggregation: Service usage and metrics can be viewed across many namespaces or teams, such as a Postgres Operator running hundreds of databases.  \n\nOpenShit Metering feature is managed by the metering operator. The metering operator depends on two components.\n\n- a database engine [Presto](https://prestodb.io). Presto is a distributed SQL database written in Java.  Presto can use several connectors, for the metering operator, it is configured to use [Hive](https://hive.apache.org), a data warehousing application with distributed storage. See the [OpenShift Document](https://docs.openshift.com/container-platform/4.3/metering/configuring_metering/metering-configure-hive-metastore.html) for detailed information.\n- a reporting framework [reporting operator](https://docs.openshift.com/container-platform/4.3/metering/configuring_metering/metering-configure-reporting-operator.html).  This is the reporting engine making use of Presto data.  \n\n\n\n## Day 1 Platform\nMetering can be a Day 1 or Day 2 activity depending on whether the business requirement for metering comes at the beginning of the OpenShift install or later.  If metering is considered as important by the business, it will be included in the design phase; then, it is a Day 1 activity.  However, some enterprises may only consider metering after they go to production.  In this case, metering is a Day 2 activity. \n\nOpenShift provides a `metering operator`; however, it is not installed by default. \nYou can __install the metering operator__ via the OpenShift web console.\n\n**Day 1 Platform task for Metering:**\n- Install the metering operator    \n\n\n## Day 2 Platform\nDepending on the defined data source, metering can report either usage of the OpenShift platform, the application, or both.\nFor platform metering, you can use the data source from the OpenShift configured Prometheus. So before you start using the metering operator, you need to __verify Prometheus is collecting data__. You can then __enable the metering operator's report__ on the cluster, node, pod, PVC resources for the request, usage, and other collected information for a different period.\nFor example, the following list some of the available platform report:\n- cluster CPU usage\n- node allocatable CPU cores\n- node allocatable memory bytes \n- node capacity CPU cores\n- persistent volume claim request bytes \n- persistent volume claim usage bytes \n- pod memory request raw \n- pod persistent volume claim request info\n- pod request CPU cores \n- pod request memory bytes \n- pod usage CPU cores\n\nTo summarize these are the activities that you need to perform for Day 2 Platform on metering:\n- [Verify Prometheus is collecting data](#platform-verify)\n- [Enable the metering operator's report](#platform-enable)   \n\n\n## Day 1 Application\nIf metering is included as part of the cluster's design and installation, to prepare for Day 2 activities, please ensure that you __obtain the business requirement documentation on metering__.\n\nAs the application's data does not come preconfigured with the OpenShift configured Prometheus, you need to configure Prometheus to collect the required data.\n\n**Day 1 Application task for Metering:**\n- Obtain the business requirement documentation on metering  \n\n\n## Day 2 Application\nThe following are the Day 2 activities in configuring the metering\n- [Capture and document the business requirement](#requirement)\n- [Develop the metering report](#report)\n- [Troubleshoot the metering operator](#troubleshooting)\n- [Uninstall the metering operator](#uninstall)  \n\n## Mapping to Personas  \nTo summarize, the following lists the topics that you may want to consider for Day 2 Operations on Metering: \n\nPersona | task\n--- | ---\nSRE | Verify Prometheus is collecting data\nSRE | Enable the metering operator's report\nSRE, DevOps Engineer | Capture and document the business requirement\nDevOps Engineer | Develop the metering report \nDevOps Engineer | Troubleshoot the metering operator \nDevOps Engineer | Uninstall the metering operator\n\n## Platform tasks\n\n<a name=\"platform-verify\"></a>\n\n## Verify Prometheus is collecting data: [SRE]\nSetting up metering is covered in the Application tasks section later in the chapter. Metering requires data, and for OpenShift, the data collection to generate report comes predominantly from the Prometheus that comes with OpenShift. You can only get a good metering report if the data are valid and comes regularly.  Therefore an important activity for Day 2 platform is to ensure that Prometheus is collecting data.\n\nInformation about Prometheus can be found in the [Monitoring](../Monitoring) section.\n\n<a name=\"platform-enable\"></a>\n\n## Enable the metering operator's report: [SRE]\nThe metering operator is not installed by default.  So if this activity has not been performed, you need to install the metering operator first.\n\nOnce you have a good stream of metrics data from Prometheus, you need to enable the metering operator. \n\nOpenShift Metering make use of the following 4 CRD (Custom Resource Definition)\n- __MeteringConfig__ to contain the configuration option.\n- __Reports__ specifies the _ReportDataSources_ to use, when, and how often the _ReportQueries_ to run.\n- __ReportDataSources__ specifies the database connection.\n- __ReportQueries__ specifies the queries to use.\n\nBefore you configure your metering, you need to ensure that you have enough compute capacity such as _StorageClass_ and _worker node_ to perform metering. You can find the detailed information in the [OpenShift Documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-installing-metering.html#metering-install-prerequisites_installing-metering).\n\nOnce you ascertain that you had the required compute capacity, you can perform the installation.  The installation steps are detailed in the [OpenShift Documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-installing-metering.html), here is the summary:\n\nThe following steps install the metering function.\n- Install the Metering Operator\n- Install the Metering Stack including creating the MeteringConfig CRD, configuring the persistent storage and configuring the hive meta store\n- Verify the installation\n\nThe following are the configuration options that may need to be considered on metering:\n- Resource Request and Limit  \n- Node Selector\n- Configuring the persistent storage\n- Configuring the hive metastore\n- Configuring the reporting-operator\n- Optional: Correlating Cluster usage to Billing Information\n\nAll the above information is well described in [the OpenShift 4.3 Metering documentation](https://docs.openshift.com/container-platform/4.3/metering/configuring-metering/metering-about-configuring.html)\n\n\n## Application tasks\n\n<a name=\"requirement\"></a>\n\n## Capture and document the business requirement: [ SRE, DevOps Engineer ]\nAt the end of the day, the reason that you perform metering is to produce a report per the business requirement. OpenShift provides the `metering operator`.  The `metering operator` comes with the `reporting operator`.  The `reporting operator` comes with some metering queries and reports.  However, the business requirement might require reports in a certain format that is different from what is provided out of the box.  A lot of the Day 2 activities on metering will be to generate queries and reports to fulfill the business requirement.\n\nAs part of the activities in fulfilling your business requirement, you need to verify that you can get the data from the source of data for your report. \nMetering focuses primarily on in-cluster metric data using Prometheus as a default data source. This enables users of metering to do reporting on pods, namespaces, and most other Kubernetes resources.  You might need to look at the Prometheus monitoring metrics first, which are discussed further in this repository [Monitoring](../Monitoring) chapter.\n\nOnce you identify the data, you put that into the configuration stored in the custom resource definition of the operator.  The operator will use this information to create tables and view in Presto, the database component of the metering operator.  The user then creates SQL queries to extract this data and create the required metering report.\n\n> As in any software development activities, when you develop your report design, it is essential to document the business requirement, design decision, and the design of your queries and reports.\n\n<a name=\"report\"></a>\n\n## Develop the metering report: [ DevOps Engineer ]\nThe first step in getting the metering report is to install and configure the metering operator if it is not installed yet.  See the Platform tasks for the activities.  It is recommended for you to generate the platform metering report first, as the required Prometheus data source has been preconfigured.  A good platform metering report ensures that the metering operator works using the default configuration.\n\nOnce you verify that your metering operator works, you most likely will spend most on your day-2 activities on metering producing reports as per the business requirement.\n\nOpenShift comes with preconfigured _ReportDataSources_ and _ReportQueries_ that the user can start using.  _Report_ CRD is used to define the schedule of the report run.\n\nThe user can write a custom report, and an example of a custom report can be found in the [documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-usage-examples.html).\n\n<a name=\"troubleshooting\"></a>\n\n## Troubleshoot the metering operator: [ DevOps Engineer ]\nThese are basic causes for metering not to work:\n- Not enough compute resources  \n- StorageClass is not configured\n- Secret not configured correctly\n\nSome of the debugging steps that can be performed:\n- Reporting Operator Logs\n- Query Presto using presto command-line interface\n- Query Hive using beeline\n- Go through the Hive web UI and HDFS UI.  You first need to configure port-forwarding to expose the UI first.\n- Access the Ansible Logs.  Metering uses Ansible, and Ansible logs might provide some information.\n\nPlease refer to the [Troubleshooting Guide](https://docs.openshift.com/container-platform/4.3/metering/metering-troubleshooting-debugging.html) for more information.  \n\n<a name=\"uninstall\"></a>\n\n## Uninstall the metering operator: [ DevOps Engineer]\nYou can uninstall the metering operator by going to the web console as a cluster administrator, then select from the menu `Operators > Installed Operators`.  Find the metering operator and then choose `Uninstall Operator` from the action menu.\n\n\nPlease refer to the [Uninstalling metering](\nhttps://docs.openshift.com/container-platform/4.3/metering/metering-uninstall.html) for more information.   \n\n\n## Implementing Metering\nThe Metering Operator is the technology that works with the Kubernetes as well as the OpenShift cluster.\n\n## Kubernetes\nThe following are collection of links related to the Metering Operator.\n- [Information from CoreOS documentation](https://coreos.com/blog/introducing-operator-framework-metering)\n- [Git pages on operator-metering](https://github.com/operator-framework/operator-metering/blob/master/Documentation/metering-architecture.md)\n- [Git pages on operator-metering installation](https://github.com/operator-framework/operator-metering/blob/master/Documentation/install-metering.md)\n- [Git pages on operator-metering configuration](https://github.com/operator-framework/operator-metering/blob/master/Documentation/metering-config.md)   \n\n\n## OpenShift\nThe information we provided in the previous sections in this document is based on the OpenShift Metering feature.  \nThe following is a link related to OpenShift metering.\n- [OpenShift 4.3 documentation on Metering](https://docs.openshift.com/container-platform/4.3/metering/metering-about-metering.html)   \n\n\n## On IBM Cloud (Managed OpenShift)\nn/a   \n\n## With IBM Cloud Pak for MCM\nThe following is a link related to IBM Cloud Pak for Multicloud Management Metering feature.\n- [IBM Cloud Pak for MCM metering](https://www.ibm.com/support/knowledgecenter/SSFC4F_1.2.0/admin/metering_service_mcm.html)  \n\n\n## Others\nn/a  \n\n## Other consideration\nn/a   \n\n","type":"Mdx","contentDigest":"2dafe3e1cc608fb5d5d3622a5b23661c","counter":520,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"OpenShift Platform Day2 - Metering","description":"OpenShift Day2 Metering","keywords":"OpenShift, day2, metering"},"exports":{},"rawBody":"---\ntitle: OpenShift Platform Day2 - Metering\ndescription: OpenShift Day2 Metering\nkeywords: 'OpenShift, day2, metering'\n---\n\n## Metering Overview\nMetering is an essential tool for organizations that use capacity from a Kubernetes cluster to run their services, as well as for IT departments that manage these clusters. In the past, many departments tended to overestimate their resource needs. This could easily result in wasted capacity and wasted capital.\n\nManagement teams want to understand more concretely where budget is spent and by whom, and for which service. Metering provides that information, providing an understanding of how much it costs to run specific services, while also providing usage information that can lead to improved budgeting and capacity planning. With this information, IT Operation can also internally bill departments to reflect the costs directly associated with their actual infrastructure usage, driving accountability for service costs. This helps to eliminate some of the more manual IT “plumbing” work in tallying costs and usage by hand or managing spreadsheets. By using metering, IT teams can free up their time to tackle bigger problems and even drive business-wide innovation.  \n\nHere are some examples of how metering could be applied in the real world:  \n- Cloud budgeting: Teams can gain insight into how cloud resources are being used, especially in autoscaled clusters or hybrid cloud deployments.  \n- Cloud billing: Resource usage can be tracked by billing codes or labels that reflect your internal hierarchy.\n- Telemetry/aggregation: Service usage and metrics can be viewed across many namespaces or teams, such as a Postgres Operator running hundreds of databases.  \n\nOpenShit Metering feature is managed by the metering operator. The metering operator depends on two components.\n\n- a database engine [Presto](https://prestodb.io). Presto is a distributed SQL database written in Java.  Presto can use several connectors, for the metering operator, it is configured to use [Hive](https://hive.apache.org), a data warehousing application with distributed storage. See the [OpenShift Document](https://docs.openshift.com/container-platform/4.3/metering/configuring_metering/metering-configure-hive-metastore.html) for detailed information.\n- a reporting framework [reporting operator](https://docs.openshift.com/container-platform/4.3/metering/configuring_metering/metering-configure-reporting-operator.html).  This is the reporting engine making use of Presto data.  \n\n\n\n## Day 1 Platform\nMetering can be a Day 1 or Day 2 activity depending on whether the business requirement for metering comes at the beginning of the OpenShift install or later.  If metering is considered as important by the business, it will be included in the design phase; then, it is a Day 1 activity.  However, some enterprises may only consider metering after they go to production.  In this case, metering is a Day 2 activity. \n\nOpenShift provides a `metering operator`; however, it is not installed by default. \nYou can __install the metering operator__ via the OpenShift web console.\n\n**Day 1 Platform task for Metering:**\n- Install the metering operator    \n\n\n## Day 2 Platform\nDepending on the defined data source, metering can report either usage of the OpenShift platform, the application, or both.\nFor platform metering, you can use the data source from the OpenShift configured Prometheus. So before you start using the metering operator, you need to __verify Prometheus is collecting data__. You can then __enable the metering operator's report__ on the cluster, node, pod, PVC resources for the request, usage, and other collected information for a different period.\nFor example, the following list some of the available platform report:\n- cluster CPU usage\n- node allocatable CPU cores\n- node allocatable memory bytes \n- node capacity CPU cores\n- persistent volume claim request bytes \n- persistent volume claim usage bytes \n- pod memory request raw \n- pod persistent volume claim request info\n- pod request CPU cores \n- pod request memory bytes \n- pod usage CPU cores\n\nTo summarize these are the activities that you need to perform for Day 2 Platform on metering:\n- [Verify Prometheus is collecting data](#platform-verify)\n- [Enable the metering operator's report](#platform-enable)   \n\n\n## Day 1 Application\nIf metering is included as part of the cluster's design and installation, to prepare for Day 2 activities, please ensure that you __obtain the business requirement documentation on metering__.\n\nAs the application's data does not come preconfigured with the OpenShift configured Prometheus, you need to configure Prometheus to collect the required data.\n\n**Day 1 Application task for Metering:**\n- Obtain the business requirement documentation on metering  \n\n\n## Day 2 Application\nThe following are the Day 2 activities in configuring the metering\n- [Capture and document the business requirement](#requirement)\n- [Develop the metering report](#report)\n- [Troubleshoot the metering operator](#troubleshooting)\n- [Uninstall the metering operator](#uninstall)  \n\n## Mapping to Personas  \nTo summarize, the following lists the topics that you may want to consider for Day 2 Operations on Metering: \n\nPersona | task\n--- | ---\nSRE | Verify Prometheus is collecting data\nSRE | Enable the metering operator's report\nSRE, DevOps Engineer | Capture and document the business requirement\nDevOps Engineer | Develop the metering report \nDevOps Engineer | Troubleshoot the metering operator \nDevOps Engineer | Uninstall the metering operator\n\n## Platform tasks\n\n<a name=\"platform-verify\"></a>\n\n## Verify Prometheus is collecting data: [SRE]\nSetting up metering is covered in the Application tasks section later in the chapter. Metering requires data, and for OpenShift, the data collection to generate report comes predominantly from the Prometheus that comes with OpenShift. You can only get a good metering report if the data are valid and comes regularly.  Therefore an important activity for Day 2 platform is to ensure that Prometheus is collecting data.\n\nInformation about Prometheus can be found in the [Monitoring](../Monitoring) section.\n\n<a name=\"platform-enable\"></a>\n\n## Enable the metering operator's report: [SRE]\nThe metering operator is not installed by default.  So if this activity has not been performed, you need to install the metering operator first.\n\nOnce you have a good stream of metrics data from Prometheus, you need to enable the metering operator. \n\nOpenShift Metering make use of the following 4 CRD (Custom Resource Definition)\n- __MeteringConfig__ to contain the configuration option.\n- __Reports__ specifies the _ReportDataSources_ to use, when, and how often the _ReportQueries_ to run.\n- __ReportDataSources__ specifies the database connection.\n- __ReportQueries__ specifies the queries to use.\n\nBefore you configure your metering, you need to ensure that you have enough compute capacity such as _StorageClass_ and _worker node_ to perform metering. You can find the detailed information in the [OpenShift Documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-installing-metering.html#metering-install-prerequisites_installing-metering).\n\nOnce you ascertain that you had the required compute capacity, you can perform the installation.  The installation steps are detailed in the [OpenShift Documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-installing-metering.html), here is the summary:\n\nThe following steps install the metering function.\n- Install the Metering Operator\n- Install the Metering Stack including creating the MeteringConfig CRD, configuring the persistent storage and configuring the hive meta store\n- Verify the installation\n\nThe following are the configuration options that may need to be considered on metering:\n- Resource Request and Limit  \n- Node Selector\n- Configuring the persistent storage\n- Configuring the hive metastore\n- Configuring the reporting-operator\n- Optional: Correlating Cluster usage to Billing Information\n\nAll the above information is well described in [the OpenShift 4.3 Metering documentation](https://docs.openshift.com/container-platform/4.3/metering/configuring-metering/metering-about-configuring.html)\n\n\n## Application tasks\n\n<a name=\"requirement\"></a>\n\n## Capture and document the business requirement: [ SRE, DevOps Engineer ]\nAt the end of the day, the reason that you perform metering is to produce a report per the business requirement. OpenShift provides the `metering operator`.  The `metering operator` comes with the `reporting operator`.  The `reporting operator` comes with some metering queries and reports.  However, the business requirement might require reports in a certain format that is different from what is provided out of the box.  A lot of the Day 2 activities on metering will be to generate queries and reports to fulfill the business requirement.\n\nAs part of the activities in fulfilling your business requirement, you need to verify that you can get the data from the source of data for your report. \nMetering focuses primarily on in-cluster metric data using Prometheus as a default data source. This enables users of metering to do reporting on pods, namespaces, and most other Kubernetes resources.  You might need to look at the Prometheus monitoring metrics first, which are discussed further in this repository [Monitoring](../Monitoring) chapter.\n\nOnce you identify the data, you put that into the configuration stored in the custom resource definition of the operator.  The operator will use this information to create tables and view in Presto, the database component of the metering operator.  The user then creates SQL queries to extract this data and create the required metering report.\n\n> As in any software development activities, when you develop your report design, it is essential to document the business requirement, design decision, and the design of your queries and reports.\n\n<a name=\"report\"></a>\n\n## Develop the metering report: [ DevOps Engineer ]\nThe first step in getting the metering report is to install and configure the metering operator if it is not installed yet.  See the Platform tasks for the activities.  It is recommended for you to generate the platform metering report first, as the required Prometheus data source has been preconfigured.  A good platform metering report ensures that the metering operator works using the default configuration.\n\nOnce you verify that your metering operator works, you most likely will spend most on your day-2 activities on metering producing reports as per the business requirement.\n\nOpenShift comes with preconfigured _ReportDataSources_ and _ReportQueries_ that the user can start using.  _Report_ CRD is used to define the schedule of the report run.\n\nThe user can write a custom report, and an example of a custom report can be found in the [documentation](https://docs.openshift.com/container-platform/4.3/metering/metering-usage-examples.html).\n\n<a name=\"troubleshooting\"></a>\n\n## Troubleshoot the metering operator: [ DevOps Engineer ]\nThese are basic causes for metering not to work:\n- Not enough compute resources  \n- StorageClass is not configured\n- Secret not configured correctly\n\nSome of the debugging steps that can be performed:\n- Reporting Operator Logs\n- Query Presto using presto command-line interface\n- Query Hive using beeline\n- Go through the Hive web UI and HDFS UI.  You first need to configure port-forwarding to expose the UI first.\n- Access the Ansible Logs.  Metering uses Ansible, and Ansible logs might provide some information.\n\nPlease refer to the [Troubleshooting Guide](https://docs.openshift.com/container-platform/4.3/metering/metering-troubleshooting-debugging.html) for more information.  \n\n<a name=\"uninstall\"></a>\n\n## Uninstall the metering operator: [ DevOps Engineer]\nYou can uninstall the metering operator by going to the web console as a cluster administrator, then select from the menu `Operators > Installed Operators`.  Find the metering operator and then choose `Uninstall Operator` from the action menu.\n\n\nPlease refer to the [Uninstalling metering](\nhttps://docs.openshift.com/container-platform/4.3/metering/metering-uninstall.html) for more information.   \n\n\n## Implementing Metering\nThe Metering Operator is the technology that works with the Kubernetes as well as the OpenShift cluster.\n\n## Kubernetes\nThe following are collection of links related to the Metering Operator.\n- [Information from CoreOS documentation](https://coreos.com/blog/introducing-operator-framework-metering)\n- [Git pages on operator-metering](https://github.com/operator-framework/operator-metering/blob/master/Documentation/metering-architecture.md)\n- [Git pages on operator-metering installation](https://github.com/operator-framework/operator-metering/blob/master/Documentation/install-metering.md)\n- [Git pages on operator-metering configuration](https://github.com/operator-framework/operator-metering/blob/master/Documentation/metering-config.md)   \n\n\n## OpenShift\nThe information we provided in the previous sections in this document is based on the OpenShift Metering feature.  \nThe following is a link related to OpenShift metering.\n- [OpenShift 4.3 documentation on Metering](https://docs.openshift.com/container-platform/4.3/metering/metering-about-metering.html)   \n\n\n## On IBM Cloud (Managed OpenShift)\nn/a   \n\n## With IBM Cloud Pak for MCM\nThe following is a link related to IBM Cloud Pak for Multicloud Management Metering feature.\n- [IBM Cloud Pak for MCM metering](https://www.ibm.com/support/knowledgecenter/SSFC4F_1.2.0/admin/metering_service_mcm.html)  \n\n\n## Others\nn/a  \n\n## Other consideration\nn/a   \n\n","fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/cloudpak8s/src/pages/day2/Metering/index.mdx"}}}}