{"componentChunkName":"component---src-pages-day-2-monitoring-index-mdx","path":"/day2/Monitoring/","result":{"pageContext":{"frontmatter":{"title":"OpenShift Platform Day2 - Monitoring and Performance","description":"OpenShift Day2 Monitoring","keywords":"OpenShift, day2, monitoring"},"relativePagePath":"/day2/Monitoring/index.mdx","titleType":"page","MdxNode":{"id":"fd2f7eda-1490-515b-a69b-d226bce8708b","children":[],"parent":"6f8856ff-db6d-5c67-82d8-736a428082a6","internal":{"content":"---\ntitle: OpenShift Platform Day2 - Monitoring and Performance\ndescription: OpenShift Day2 Monitoring\nkeywords: 'OpenShift, day2, monitoring'\n---\n\n## Monitoring Overview\nThe approach an organization takes to Monitoring and Alerting on events of importance is one of the most important considerations for an enterprise. It is often overlooked by organizations and at times haphazardly implemented at the last minute. In many cases it does not provide the proper coverage of an application and its components.\n\nOut of the box, the Red Hat OpenShift Container Platform provides the ability to monitor the OpenShift platform. As described below and at the links included herein, this capability should be leveraged and integrated with your enterprise event management and application performance management.\n\nThis section is based on OpenShift version 4.3. Please be sure to check the Red Hat documentation for the installed version at your location.\n\nPlease read the [Red Hat documentation](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/about-cluster-monitoring.html) for more information and guidance.\n\nThe goal of any monitoring endeavor is to provide observability of the platform and applications so that one can \"ask\" questions to spot anomalies and un-cover the cause of an unplanned issue as quickly as possible.\n\n## Day 1 Platform\nThere are a couple of tasks for Day 1 Infrastructure as follows.  \n\n- Installation of the Monitoring Stack is default\n\n  Implementation of the OpenShift Infrastructure Monitoring Stack is completed during OpenShift installation. Should there be a need for additional infrastructure related monitoring. Whether it be a third party solution from IBM or others, these tools should be planned and allocated for during this phase.\nThe monitoring stack imposes additional resource requirements. Consult the computing resources recommendations in [Scaling the Cluster Monitoring Operator](https://docs.openshift.com/container-platform/4.3/scalability_and_performance/scaling-cluster-monitoring-operator.html) and verify that you have sufficient resources.  \n\n- Perform Customization of Monitoring Stack\n\n  Note that customization of the default OpenShift Infrastructure Monitoring Stack is limited. Supported customizations include adding persistent storage to monitoring components, routing notification of the defined monitoring alerts and so on. Adding new alerts or changing the predefined dashboards is not supported (as of OpenShift 4.3).\n  Any configuration that is not explicitly documented [here](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/configuring-the-monitoring-stack.html) is not supported.\n\n- [Configure Alert Manager to forward to the correct Destination](#alerting)\n\n## Day 2 Platform\n\n### Verify Platform Monitoring\nNow that the Platform is up and running the Out of the box monitoring should \nbe verified as operational.\n\n- [Viewing performance data in the login dashboard](#OpenshiftDashboard)\n- [Viewing Prometheus metrics](#Using-Prometheus)\n- [Confirm the default Grafana dashboards are available](#Using-Grafana)\n- [Verify actionable alerts are flowing to the correct destination](#alerting)     \n\n\n## Day 1 Application\n\nThough tightly coupled Application and Infrastructure monitoring are quite different. Each application presents its own characteristics which we need to monitor. For example with a Java app we may want to keep an eye on heap utilization and an app that is streaming video we may need to focus more on disk performance. The unique attributes and limits of the application should be identified in the development phase along with their affect on the infrastructure.\n\nThe cluster monitoring stack in version 4.3 includes a **Tech Preview** for monitoring your own service. Important agreement and support information [here](https://docs.openshift.com/container-platform/4.3/monitoring/monitoring-your-own-services.html).\n\n**[Quote from Red Hat Online document](https://docs.openshift.com/container-platform/4.3/monitoring/monitoring-your-own-services.html)**\n>Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.\n\nAt this time in order to reduce risk for critical applications,  we recommend installing service/application monitoring outside of this monitoring stack.  \n\nKeep in mind, the Platform is monitored quite nicely out of the box. There are numerous solutions available for Application Performance Management. Such as:\n- [IBM Cloud App Management](https://www.ibm.com/support/knowledgecenter/SS8G7U_18.2.0/com.ibm.app.mgmt.doc/welcome.htm)\n- [Sysdig](https://sysdig.com/)\n- [Prometheus](https://prometheus.io/)\n- [New Relic](https://newrelic.com/)\n- and others\n\nAll deployed applications also require the business appropriate level of run time monitoring.\nKey Considerations:\n- Leverage Shift left testing of the application to understand the performance characteristics  \n- Monitor the type of Run time (Java, Nodejs, Go. etc)\n         - Logging\n         - Tracing\n         - Metrics: [Golden Signals](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/), [RED](https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/) or [USE](http://www.brendangregg.com/usemethod.html) Methods are recommended\n\n- Determine depth of Monitoring based on business criticality - Beyond Metrics, Logs and Traces, Do we require Blackbox, API Health Checks, User Experience Monitoring\n- Assess application performance for production readiness\n- Define saturation monitors - This is not always the easiest metric to figure out. For JVMs, Heap size, and garbage collection, for a streaming application, disk I/O are metrics for saturation\n- Identify run book requirements - Items such as application restart, routine maintenance garbage candidates for the runbook\n\n\nPrometheus provides exporters for the most popular run times. When implemented these exporters can monitor the most popular run times [here](https://prometheus.io/docs/instrumenting/exporters/). Exporters are also available for Blackbox testing and SNMP Monitoring. Black-box testing is a method of application testing/monitoring external to the applications (URL loads, pings metrics)\n\nYou can find out an example of application monitoring with customer installed Prometheus  [here](https://github.ibm.com/CASE/openshift-custom-app-monitoring/blob/master/README.md).\n\n We also recommend using Build to Manage practices when building your applications please see the [Points of View](https://www.ibm.com/cloud/architecture/files/service-management-pov-csmo-build-to-manage-v1.1.pdf).  \n\n\n## Day 2 Application\n\nThe APM solution of your choice should be deployed and/or the application should be instrumented to emit metrics and data  \n\n- Verify application metrics visible in the Application Monitoring solution\n- Verify initial alerts based on known application characteristics should be deployed\n- Take the time to ensure application performs as expected\n- Ensure depth of monitoring meets business application criticality Blackbox tests such as URLs loads or \"pings\", API Health Checks and Synthetic transactions should be deployed   \n\n\n## Mapping to Personas\n\n| Persona | task |\n| --- | --- |\n| SRE | Viewing performance data in the login dashboard |\n| SRE | Viewing Prometheus metrics |\n| SRE | Rendering data with the default Grafana dashboards |\n| SRE | Ensure Alert  Manager is forwarding to the desired destination |\n| SRE, DevOps Engineer | Verify actionable alerts are flowing |\n| SRE, DevOps Engineer | Verify the application metrics visible in the Application Monitoring solution |\n| SRE, DevOps Engineer | Implement alerts based on known application characteristics from testing |\n| SRE, DevOps Engineer | Ensure application performs as expected |\n| SRE, DevOps Engineer | Ensure monitoring depth meets business needs |\n\n## Monitoring Day 2 Tasks\n\n## <a name=\"OpenshiftDashboard\"></a>Viewing performance data in the login dashboard: [SRE]\nOnce deployed, the OpenShift Web Console displays a high level view of the current performance on the main OpenShift Dashboard. KPIs such as a Cluster Health Indicator, Capacity Utilization and availability across the cluster. High level cluster information,  alerts and top Pods, are displayed as well. This is a view only interface, meaning there are no integrations or extensions available.\n![ocp_login_dashboard](./images/OCP_Login_Dashboard.png)\n\n### Cluster Level Monitoring\nWhen OpenShift is deployed, the Open Source monitoring and alerting tools, [**Prometheus**](https://prometheus.io/) the Prometheus [**Alert Manager**](https://prometheus.io/docs/alerting/overview/), and visualization software [**Grafana**](https://grafana.com/), are installed.\n![prom_arch](./images/OCP_Prom_Arch.png)\n\nCombined this software is referred to as the Monitoring Stack in the Open Shift documentation. This Stack provides immediate monitoring and visualization of the OpenShift deployment infrastructure components. Several Grafana Dashboards are supplied which provide various views of the time-series data collected by Prometheus. The Dashboard shown below leverages the [USE Method](http://www.brendangregg.com/usemethod.html) (Utilization, Saturation and Errors) for visualization of overall cluster performance:\n\n![ocp_use](./images/Cluster_Use_Method.png)  \n\nSome of the other dashboards included are:\n- etcd - Metrics and etcd related performance.\n- Kubernetes Compute resources for Namespace Pods, Namespace Workloads and other Compute Related Dashboards\n- Use Method by Node\n- Prometheus Metrics\n\n***NOTE:*** When accessing Prometheus, Grafana or the Alertmanager for the first time you may need to enter your user:password again and allow the respective tool access to your account:\n![ocp_login_access](./images/OCP_Auth_Window.png)\n\n### <a name=\"Using-Prometheus\"></a>Viewing Prometheus metrics: [SRE]\nOpenShift provides a Prometheus (like) UI for viewing and generating queries against the collected data. The UI is available under the Monitoring tab by selecting metrics:\n\n![prom_ui](./images/Prom_OCP_UI.png)\n\nThe UI allows you to:\n- Generate, run and save queries\n- Run a test query, great for a quick test that the Prometheus deployment is working.\n- Launch the Prometheus Metrics UI\n\n![prom_ui](./images/OCP_PROM_QUERY.png)\n\nIn addition to the components of the stack itself, the monitoring stack provide coverage for:\n\n- CoreDNS\n- Elasticsearch (if Logging is installed)\n- Etcd\n- Fluentd (if Logging is installed)\n- HAProxy\n- Image Registry\n- Kubelets\n- Kubernetes Api Server\n- Kubernetes Controller Manager\n- Kubernetes Scheduler\n- Metering (if Metering is installed)\n- OpenShift Api Server\n- OpenShift Controller Manager\n- Operator Lifecycle Manager (OLM)\n- Telemeter client\n\nPlease see [Examining Cluster Metrics](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/examining-cluster-metrics.html) for more information on using this interface.\n\n## <a name=\"Using-Grafana\"></a>Rendering data with the default Grafana dashboards: [SRE]\nVerify Built-in Grafana Dashboards are properly working by selecting dashboards under the monitoring tab in the OpenShift Dashboard hamburger menu.\nOpen one of the available dashboards and observe the performance of the OpenShift installation.  In this example we launched the etcd dashboard.\n\n![ocp_grafana](./images/OCP_Grafana_Launch.png)\n\nThe OpenShift Grafana deployed with the Monitoring Stack does not allow for \ncustomizations. Should you desire to build your own dashboards \n(using this Prometheus data source) or need to import some of the \n[Open Shift Dashboards from the Grafana website](https://grafana.com/grafana/dashboards?search=OpenShift), \nplease see [Red Hat Blog: Custom Grafana dashboards for Red Hat OpenShift Container Platform 4](https://www.redhat.com/en/blog/custom-grafana-dashboards-red-hat-openshift-container-platform-4).\n\n## <a name=\"alerting\"></a>Alerting: [SRE]\nIncluded with the Monitoring Stack are ~120 predefined alerts. The Alert Manager is available by selecting Alerts under the monitoring tab in the web console.\n\n![alrt_mgr](./images/OCP_PROM_AlrtMGR.png)\n\nWe recommend integrating the Alert Manager and any other Monitoring tools you use with your organizations event management solution. Please see [Event management](../EventManagement) for\n- more information on using the Alert Manager UI\n- pre-defined alerts\n- notification setup\n- alert silencing and management\n\nAlso the Red Hat Documentation for managing [cluster alerts](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/managing-cluster-alerts.html).\n\nFor more information please refer to the [Alerting](../EventManagement) chapter of this repository.  \n\n## Implementing the Monitoring Stack\n\n## Kubernetes\nKubernetes itself does not include a monitoring solution. Kubernetes does emit a sufficient set of metrics which are available to the out-of-the-box Monitoring Stack or a variety of solutions from IBM and third parties.  \n\n## OpenShift\nThe included monitoring stack in OpenShift is installed by default. The operations with OpenShift monitoring stack we described in this document come with OpenShift.\n\n## OpenShift managed service on IBM Cloud  \nYou can find what solutions are available for monitoring and alerting on IBM Cloud in [here](ibmcloud).  \n\n## With IBM Cloud Pak for MCM\nIBM CloudPak for Multi Cloud Manager provides the ability to manage multiple cloud environments from a single point. Items such as Cluster configuration, Application Manager, Certificate management and Governance are available.\n\nMCM also includes IBM Cloud App Management, IBM Cloud Event Management and IBM Cloud Automation) for monitoring, alerting and managing your cluster infrastructure and applications across multiple clouds. Please note: the Multi Cloud Manager tool itself has been recently Open Sourced.\n\nMore information on this Cloud Pak is [here](https://www.ibm.com/support/knowledgecenter/SSFC4F_1.2.0/kc_welcome_cloud_pak.html).\n\n## Others Considerations\n\n### Remote Health Monitoring [SRE]\nOpenShift has a built in health monitoring system which reports data to Red Hat. This facility uses two integrated components: Telemetry and Insights Operator.\nRed Hat has chosen a select set of anonymized metric data about the health, usage, and size of your clusters and reports it to Red Hat. For more information please see this [link](https://docs.openshift.com/container-platform/4.3/support/remote_health_monitoring/about-remote-health-monitoring.html).\n\n### Available Operators [SRE & Developer]\nPlease see this [link](https://docs.openshift.com/container-platform/4.3/operators/olm-what-operators-are.html) for information about the Open Shift Operators.\n\nOpenShift provides Operators for integration with third party products such as New Relic, Sysdig, and Prometheus.\n\n### Scalable and HA Solution for Prometheus [SRE]\nShould you have the need for a solution to Federate multiple clouds and scalable and HA solution using Prometheus, [**Thanos**](https://blog.openshift.com/federated-prometheus-with-thanos-receive/) may be an solution for you.\n","type":"Mdx","contentDigest":"c0ab3aebdba73d7f82a967d4514d6929","counter":521,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"OpenShift Platform Day2 - Monitoring and Performance","description":"OpenShift Day2 Monitoring","keywords":"OpenShift, day2, monitoring"},"exports":{},"rawBody":"---\ntitle: OpenShift Platform Day2 - Monitoring and Performance\ndescription: OpenShift Day2 Monitoring\nkeywords: 'OpenShift, day2, monitoring'\n---\n\n## Monitoring Overview\nThe approach an organization takes to Monitoring and Alerting on events of importance is one of the most important considerations for an enterprise. It is often overlooked by organizations and at times haphazardly implemented at the last minute. In many cases it does not provide the proper coverage of an application and its components.\n\nOut of the box, the Red Hat OpenShift Container Platform provides the ability to monitor the OpenShift platform. As described below and at the links included herein, this capability should be leveraged and integrated with your enterprise event management and application performance management.\n\nThis section is based on OpenShift version 4.3. Please be sure to check the Red Hat documentation for the installed version at your location.\n\nPlease read the [Red Hat documentation](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/about-cluster-monitoring.html) for more information and guidance.\n\nThe goal of any monitoring endeavor is to provide observability of the platform and applications so that one can \"ask\" questions to spot anomalies and un-cover the cause of an unplanned issue as quickly as possible.\n\n## Day 1 Platform\nThere are a couple of tasks for Day 1 Infrastructure as follows.  \n\n- Installation of the Monitoring Stack is default\n\n  Implementation of the OpenShift Infrastructure Monitoring Stack is completed during OpenShift installation. Should there be a need for additional infrastructure related monitoring. Whether it be a third party solution from IBM or others, these tools should be planned and allocated for during this phase.\nThe monitoring stack imposes additional resource requirements. Consult the computing resources recommendations in [Scaling the Cluster Monitoring Operator](https://docs.openshift.com/container-platform/4.3/scalability_and_performance/scaling-cluster-monitoring-operator.html) and verify that you have sufficient resources.  \n\n- Perform Customization of Monitoring Stack\n\n  Note that customization of the default OpenShift Infrastructure Monitoring Stack is limited. Supported customizations include adding persistent storage to monitoring components, routing notification of the defined monitoring alerts and so on. Adding new alerts or changing the predefined dashboards is not supported (as of OpenShift 4.3).\n  Any configuration that is not explicitly documented [here](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/configuring-the-monitoring-stack.html) is not supported.\n\n- [Configure Alert Manager to forward to the correct Destination](#alerting)\n\n## Day 2 Platform\n\n### Verify Platform Monitoring\nNow that the Platform is up and running the Out of the box monitoring should \nbe verified as operational.\n\n- [Viewing performance data in the login dashboard](#OpenshiftDashboard)\n- [Viewing Prometheus metrics](#Using-Prometheus)\n- [Confirm the default Grafana dashboards are available](#Using-Grafana)\n- [Verify actionable alerts are flowing to the correct destination](#alerting)     \n\n\n## Day 1 Application\n\nThough tightly coupled Application and Infrastructure monitoring are quite different. Each application presents its own characteristics which we need to monitor. For example with a Java app we may want to keep an eye on heap utilization and an app that is streaming video we may need to focus more on disk performance. The unique attributes and limits of the application should be identified in the development phase along with their affect on the infrastructure.\n\nThe cluster monitoring stack in version 4.3 includes a **Tech Preview** for monitoring your own service. Important agreement and support information [here](https://docs.openshift.com/container-platform/4.3/monitoring/monitoring-your-own-services.html).\n\n**[Quote from Red Hat Online document](https://docs.openshift.com/container-platform/4.3/monitoring/monitoring-your-own-services.html)**\n>Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.\n\nAt this time in order to reduce risk for critical applications,  we recommend installing service/application monitoring outside of this monitoring stack.  \n\nKeep in mind, the Platform is monitored quite nicely out of the box. There are numerous solutions available for Application Performance Management. Such as:\n- [IBM Cloud App Management](https://www.ibm.com/support/knowledgecenter/SS8G7U_18.2.0/com.ibm.app.mgmt.doc/welcome.htm)\n- [Sysdig](https://sysdig.com/)\n- [Prometheus](https://prometheus.io/)\n- [New Relic](https://newrelic.com/)\n- and others\n\nAll deployed applications also require the business appropriate level of run time monitoring.\nKey Considerations:\n- Leverage Shift left testing of the application to understand the performance characteristics  \n- Monitor the type of Run time (Java, Nodejs, Go. etc)\n         - Logging\n         - Tracing\n         - Metrics: [Golden Signals](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/), [RED](https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/) or [USE](http://www.brendangregg.com/usemethod.html) Methods are recommended\n\n- Determine depth of Monitoring based on business criticality - Beyond Metrics, Logs and Traces, Do we require Blackbox, API Health Checks, User Experience Monitoring\n- Assess application performance for production readiness\n- Define saturation monitors - This is not always the easiest metric to figure out. For JVMs, Heap size, and garbage collection, for a streaming application, disk I/O are metrics for saturation\n- Identify run book requirements - Items such as application restart, routine maintenance garbage candidates for the runbook\n\n\nPrometheus provides exporters for the most popular run times. When implemented these exporters can monitor the most popular run times [here](https://prometheus.io/docs/instrumenting/exporters/). Exporters are also available for Blackbox testing and SNMP Monitoring. Black-box testing is a method of application testing/monitoring external to the applications (URL loads, pings metrics)\n\nYou can find out an example of application monitoring with customer installed Prometheus  [here](https://github.ibm.com/CASE/openshift-custom-app-monitoring/blob/master/README.md).\n\n We also recommend using Build to Manage practices when building your applications please see the [Points of View](https://www.ibm.com/cloud/architecture/files/service-management-pov-csmo-build-to-manage-v1.1.pdf).  \n\n\n## Day 2 Application\n\nThe APM solution of your choice should be deployed and/or the application should be instrumented to emit metrics and data  \n\n- Verify application metrics visible in the Application Monitoring solution\n- Verify initial alerts based on known application characteristics should be deployed\n- Take the time to ensure application performs as expected\n- Ensure depth of monitoring meets business application criticality Blackbox tests such as URLs loads or \"pings\", API Health Checks and Synthetic transactions should be deployed   \n\n\n## Mapping to Personas\n\n| Persona | task |\n| --- | --- |\n| SRE | Viewing performance data in the login dashboard |\n| SRE | Viewing Prometheus metrics |\n| SRE | Rendering data with the default Grafana dashboards |\n| SRE | Ensure Alert  Manager is forwarding to the desired destination |\n| SRE, DevOps Engineer | Verify actionable alerts are flowing |\n| SRE, DevOps Engineer | Verify the application metrics visible in the Application Monitoring solution |\n| SRE, DevOps Engineer | Implement alerts based on known application characteristics from testing |\n| SRE, DevOps Engineer | Ensure application performs as expected |\n| SRE, DevOps Engineer | Ensure monitoring depth meets business needs |\n\n## Monitoring Day 2 Tasks\n\n## <a name=\"OpenshiftDashboard\"></a>Viewing performance data in the login dashboard: [SRE]\nOnce deployed, the OpenShift Web Console displays a high level view of the current performance on the main OpenShift Dashboard. KPIs such as a Cluster Health Indicator, Capacity Utilization and availability across the cluster. High level cluster information,  alerts and top Pods, are displayed as well. This is a view only interface, meaning there are no integrations or extensions available.\n![ocp_login_dashboard](./images/OCP_Login_Dashboard.png)\n\n### Cluster Level Monitoring\nWhen OpenShift is deployed, the Open Source monitoring and alerting tools, [**Prometheus**](https://prometheus.io/) the Prometheus [**Alert Manager**](https://prometheus.io/docs/alerting/overview/), and visualization software [**Grafana**](https://grafana.com/), are installed.\n![prom_arch](./images/OCP_Prom_Arch.png)\n\nCombined this software is referred to as the Monitoring Stack in the Open Shift documentation. This Stack provides immediate monitoring and visualization of the OpenShift deployment infrastructure components. Several Grafana Dashboards are supplied which provide various views of the time-series data collected by Prometheus. The Dashboard shown below leverages the [USE Method](http://www.brendangregg.com/usemethod.html) (Utilization, Saturation and Errors) for visualization of overall cluster performance:\n\n![ocp_use](./images/Cluster_Use_Method.png)  \n\nSome of the other dashboards included are:\n- etcd - Metrics and etcd related performance.\n- Kubernetes Compute resources for Namespace Pods, Namespace Workloads and other Compute Related Dashboards\n- Use Method by Node\n- Prometheus Metrics\n\n***NOTE:*** When accessing Prometheus, Grafana or the Alertmanager for the first time you may need to enter your user:password again and allow the respective tool access to your account:\n![ocp_login_access](./images/OCP_Auth_Window.png)\n\n### <a name=\"Using-Prometheus\"></a>Viewing Prometheus metrics: [SRE]\nOpenShift provides a Prometheus (like) UI for viewing and generating queries against the collected data. The UI is available under the Monitoring tab by selecting metrics:\n\n![prom_ui](./images/Prom_OCP_UI.png)\n\nThe UI allows you to:\n- Generate, run and save queries\n- Run a test query, great for a quick test that the Prometheus deployment is working.\n- Launch the Prometheus Metrics UI\n\n![prom_ui](./images/OCP_PROM_QUERY.png)\n\nIn addition to the components of the stack itself, the monitoring stack provide coverage for:\n\n- CoreDNS\n- Elasticsearch (if Logging is installed)\n- Etcd\n- Fluentd (if Logging is installed)\n- HAProxy\n- Image Registry\n- Kubelets\n- Kubernetes Api Server\n- Kubernetes Controller Manager\n- Kubernetes Scheduler\n- Metering (if Metering is installed)\n- OpenShift Api Server\n- OpenShift Controller Manager\n- Operator Lifecycle Manager (OLM)\n- Telemeter client\n\nPlease see [Examining Cluster Metrics](https://docs.openshift.com/container-platform/4.3/monitoring/cluster-monitoring/examining-cluster-metrics.html) for more information on using this interface.\n\n## <a name=\"Using-Grafana\"></a>Rendering data with the default Grafana dashboards: [SRE]\nVerify Built-in Grafana Dashboards are properly working by selecting dashboards under the monitoring tab in the OpenShift Dashboard hamburger menu.\nOpen one of the available dashboards and observe the performance of the OpenShift installation.  In this example we launched the etcd dashboard.\n\n![ocp_grafana](./images/OCP_Grafana_Launch.png)\n\nThe OpenShift Grafana deployed with the Monitoring Stack does not allow for \ncustomizations. Should you desire to build your own dashboards \n(using this Prometheus data source) or need to import some of the \n[Open Shift Dashboards from the Grafana website](https://grafana.com/grafana/dashboards?search=OpenShift), \nplease see [Red Hat Blog: Custom Grafana dashboards for Red Hat OpenShift Container Platform 4](https://www.redhat.com/en/blog/custom-grafana-dashboards-red-hat-openshift-container-platform-4).\n\n## <a name=\"alerting\"></a>Alerting: [SRE]\nIncluded with the Monitoring Stack are ~120 predefined alerts. The Alert Manager is available by selecting Alerts under the monitoring tab in the web console.\n\n![alrt_mgr](./images/OCP_PROM_AlrtMGR.png)\n\nWe recommend integrating the Alert Manager and any other Monitoring tools you use with your organizations event management solution. Please see [Event management](../EventManagement) for\n- more information on using the Alert Manager UI\n- pre-defined alerts\n- notification setup\n- alert silencing and management\n\nAlso the Red Hat Documentation for managing [cluster alerts](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/managing-cluster-alerts.html).\n\nFor more information please refer to the [Alerting](../EventManagement) chapter of this repository.  \n\n## Implementing the Monitoring Stack\n\n## Kubernetes\nKubernetes itself does not include a monitoring solution. Kubernetes does emit a sufficient set of metrics which are available to the out-of-the-box Monitoring Stack or a variety of solutions from IBM and third parties.  \n\n## OpenShift\nThe included monitoring stack in OpenShift is installed by default. The operations with OpenShift monitoring stack we described in this document come with OpenShift.\n\n## OpenShift managed service on IBM Cloud  \nYou can find what solutions are available for monitoring and alerting on IBM Cloud in [here](ibmcloud).  \n\n## With IBM Cloud Pak for MCM\nIBM CloudPak for Multi Cloud Manager provides the ability to manage multiple cloud environments from a single point. Items such as Cluster configuration, Application Manager, Certificate management and Governance are available.\n\nMCM also includes IBM Cloud App Management, IBM Cloud Event Management and IBM Cloud Automation) for monitoring, alerting and managing your cluster infrastructure and applications across multiple clouds. Please note: the Multi Cloud Manager tool itself has been recently Open Sourced.\n\nMore information on this Cloud Pak is [here](https://www.ibm.com/support/knowledgecenter/SSFC4F_1.2.0/kc_welcome_cloud_pak.html).\n\n## Others Considerations\n\n### Remote Health Monitoring [SRE]\nOpenShift has a built in health monitoring system which reports data to Red Hat. This facility uses two integrated components: Telemetry and Insights Operator.\nRed Hat has chosen a select set of anonymized metric data about the health, usage, and size of your clusters and reports it to Red Hat. For more information please see this [link](https://docs.openshift.com/container-platform/4.3/support/remote_health_monitoring/about-remote-health-monitoring.html).\n\n### Available Operators [SRE & Developer]\nPlease see this [link](https://docs.openshift.com/container-platform/4.3/operators/olm-what-operators-are.html) for information about the Open Shift Operators.\n\nOpenShift provides Operators for integration with third party products such as New Relic, Sysdig, and Prometheus.\n\n### Scalable and HA Solution for Prometheus [SRE]\nShould you have the need for a solution to Federate multiple clouds and scalable and HA solution using Prometheus, [**Thanos**](https://blog.openshift.com/federated-prometheus-with-thanos-receive/) may be an solution for you.\n","fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/cloudpak8s/src/pages/day2/Monitoring/index.mdx"}}}}